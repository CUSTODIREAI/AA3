{
  "implementation": "Prepared a two-image Docker setup for DeepFaceLab on CUDA 11.8 tuned for RTX 4090. The base image includes Python 3.10, TensorFlow GPU 2.13.1, TensorFlow Addons 0.23.x, cuDNN (via CUDA 11.8 cudnn runtime), and key ML dependencies (onnxruntime-gpu, facexlib, insightface, OpenCV, etc.), plus NVIDIA runtime configuration and a non-root user. The DFL image clones DeepFaceLab at a build-arg-selectable ref (branch/tag/commit), strips pretrained assets, and provides an entrypoint wrapper. Build and test scripts handle building, tagging, exporting tarballs with SHA-256, and performing RTX 4090 smoke tests (nvidia-smi, TF GPU visibility, ONNX runtime device, DFL CLI). Docker Compose configuration and documentation guide usage and training workflow. Evidence scripts/templates are included to record image metadata and checksums.",
  "files_to_create": [
    {
      "path": "docker/dfl-base.Dockerfile",
      "content": "FROM nvidia/cuda:11.8.0-cudnn8-runtime-ubuntu22.04\n\nARG DEBIAN_FRONTEND=noninteractive\n\nLABEL org.opencontainers.image.title=\"DeepFaceLab Base (CUDA 11.8, TF 2.13.1)\" \\\n      org.opencontainers.image.description=\"Base runtime with CUDA 11.8 + cuDNN, Python 3.10, TensorFlow 2.13.1 GPU, and common ML deps for DeepFaceLab on RTX 4090\" \\\n      org.opencontainers.image.vendor=\"Custodire\" \\\n      org.opencontainers.image.licenses=\"GPL-3.0 AND Apache-2.0 AND BSD-3-Clause AND MIT\" \\\n      org.opencontainers.image.source=\"https://github.com/iperov/DeepFaceLab\"\n\n# System dependencies and NVIDIA compatibility package\nRUN apt-get update && apt-get install -y --no-install-recommends \\\n    python3 \\\n    python3-venv \\\n    python3-pip \\\n    git \\\n    ffmpeg \\\n    wget \\\n    ca-certificates \\\n    pkg-config \\\n    build-essential \\\n    libgl1 \\\n    libglib2.0-0 \\\n    libsm6 \\\n    libxext6 \\\n    libxrender1 \\\n    cuda-compat-11-8 \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Create and prepare venv\nENV VENV_PATH=/opt/venv\nRUN python3 -m venv \"$VENV_PATH\" \\\n    && \"$VENV_PATH/bin/pip\" install --upgrade pip setuptools wheel\n\n# Python dependencies pinned for CUDA 11.8 / TF 2.13.1\n# Numpy pin avoids ABI issues and matches TF 2.13 constraints.\nENV PIP_NO_CACHE_DIR=1\nRUN \"$VENV_PATH/bin/pip\" install \\\n    numpy==1.24.3 \\\n    tensorflow==2.13.1 \\\n    tensorflow-addons==0.23.0 \\\n    onnxruntime-gpu==1.16.3 \\\n    onnx==1.14.1 \\\n    opencv-python-headless==4.8.1.78 \\\n    scikit-image==0.21.0 \\\n    scikit-learn==1.3.2 \\\n    numexpr==2.8.7 \\\n    h5py==3.8.0 \\\n    matplotlib==3.7.3 \\\n    pandas==2.0.3 \\\n    tqdm==4.66.1 \\\n    psutil==5.9.5 \\\n    albumentations==1.3.1 \\\n    insightface>=0.7.3,<0.8 \\\n    facexlib==0.3.0\n\n# Non-root user and workspace\nRUN groupadd -g 1000 dfl && useradd -m -u 1000 -g 1000 -s /bin/bash dfl \\\n    && mkdir -p /workspace \\\n    && chown -R dfl:dfl /workspace\n\n# Environment configuration for TF on Ada (4090)\nENV PATH=\"$VENV_PATH/bin:$PATH\" \\\n    TF_CPP_MIN_LOG_LEVEL=1 \\\n    TF_FORCE_GPU_ALLOW_GROWTH=true \\\n    TF_GPU_ALLOCATOR=cuda_malloc_async \\\n    NVIDIA_VISIBLE_DEVICES=all \\\n    NVIDIA_DRIVER_CAPABILITIES=compute,utility,video\n\nWORKDIR /workspace\nUSER dfl\n\n# Print GPU availability at container start if run interactively\nCMD [\"python\", \"-c\", \"import tensorflow as tf; print('GPUs:', tf.config.list_physical_devices('GPU'))\"]\n"
    },
    {
      "path": "docker/dfl.Dockerfile",
      "content": "ARG BASE_IMAGE=custodire/dfl:base-cuda11.8-tf2.13.1\nFROM ${BASE_IMAGE}\n\nUSER root\n\nLABEL org.opencontainers.image.title=\"DeepFaceLab (CUDA 11.8, TF 2.13.1)\" \\\n      org.opencontainers.image.description=\"DeepFaceLab runtime on CUDA 11.8/TF 2.13.1 for RTX 4090. Excludes pretrained models.\" \\\n      org.opencontainers.image.vendor=\"Custodire\" \\\n      org.opencontainers.image.licenses=\"GPL-3.0\" \\\n      org.opencontainers.image.source=\"https://github.com/iperov/DeepFaceLab\"\n\n# Build arg for DFL ref (branch/tag/commit). Default to master.\nARG DFL_REF=master\nENV DFL_DIR=/opt/dfl/DeepFaceLab\n\n# Clone DFL at specified ref and strip large/non-redistributable dirs\nRUN set -eux; \\\n    apt-get update && apt-get install -y --no-install-recommends git ca-certificates && rm -rf /var/lib/apt/lists/*; \\\n    mkdir -p /opt/dfl; \\\n    git clone https://github.com/iperov/DeepFaceLab.git \"$DFL_DIR\"; \\\n    cd \"$DFL_DIR\"; \\\n    # Checkout to branch/tag/commit provided in DFL_REF\n    if git rev-parse --verify --quiet \"$DFL_REF\" >/dev/null; then \\\n      git checkout -q \"$DFL_REF\"; \\\n    else \\\n      git fetch --depth=1 origin \"$DFL_REF\" && git checkout -q FETCH_HEAD || echo \"DFL_REF not directly resolvable, staying on default\"; \\\n    fi; \\\n    # Record exact commit\n    git rev-parse HEAD > /opt/dfl/DFL_COMMIT; \\\n    # Remove non-essential and large assets (pretrained/workspace) from image\n    rm -rf .git pretrained workspace || true\n\n# Copy entrypoint wrapper\nCOPY --chown=dfl:dfl entrypoint.dfl.sh /usr/local/bin/dfl\nRUN chmod +x /usr/local/bin/dfl\n\n# Ensure ownership of /opt/dfl and workspace\nRUN chown -R dfl:dfl /opt/dfl /workspace\n\nUSER dfl\nWORKDIR /workspace\n\nENV DFL_HOME=/opt/dfl \\\n    DFL_DIR=/opt/dfl/DeepFaceLab\n\nENTRYPOINT [\"/usr/local/bin/dfl\"]\n# Show DFL help if no args\nCMD [\"help\"]\n"
    },
    {
      "path": "docker/dfl.dockerignore",
      "content": "# Exclude everything by default to minimize context\n**\n\n# Allow only our Dockerfiles and scripts\n!dfl-base.Dockerfile\n!dfl.Dockerfile\n!entrypoint.dfl.sh\n!build_dfl_images.sh\n!test_dfl_rtx4090.sh\n!dfl-compose.yaml\n\n# Never send local workspace/models to the daemon\nworkspace/\nmodels/\npretrained/\ncheckpoints/\noutputs/\n*.zip\n*.tar\n*.tar.gz\n*.tgz\n*.mp4\n*.mkv\n*.mov\n*.avi\n*.jpg\n*.jpeg\n*.png\n*.webp\n"
    },
    {
      "path": "docker/entrypoint.dfl.sh",
      "content": "#!/usr/bin/env bash\nset -euo pipefail\n\n# Activate venv if available\nif [ -d \"/opt/venv\" ]; then\n  # shellcheck source=/dev/null\n  source /opt/venv/bin/activate\nfi\n\n# NVIDIA / TF runtime preferences\nexport TF_CPP_MIN_LOG_LEVEL=\"1\"\nexport TF_FORCE_GPU_ALLOW_GROWTH=\"true\"\nexport TF_GPU_ALLOCATOR=\"cuda_malloc_async\"\nexport NVIDIA_VISIBLE_DEVICES=\"${NVIDIA_VISIBLE_DEVICES:-all}\"\nexport NVIDIA_DRIVER_CAPABILITIES=\"${NVIDIA_DRIVER_CAPABILITIES:-compute,utility,video}\"\n\nDFL_MAIN=\"/opt/dfl/DeepFaceLab/main.py\"\n\nif [ ! -f \"$DFL_MAIN\" ]; then\n  echo \"DeepFaceLab main not found at $DFL_MAIN\" >&2\n  exit 1\nfi\n\nif [ $# -eq 0 ] || [ \"$1\" = \"help\" ]; then\n  exec python -u \"$DFL_MAIN\" help\nelse\n  exec python -u \"$DFL_MAIN\" \"$@\"\nfi\n"
    },
    {
      "path": "docker/build_dfl_images.sh",
      "content": "#!/usr/bin/env bash\nset -euo pipefail\n\n# Configurable vars\nIMAGE_NS=\"custodire/dfl\"\nBASE_TAG=\"base-cuda11.8-tf2.13.1\"\nDFL_TAG=\"dfl-cuda11.8-tf2.13.1\"\nDFL_REF=\"master\"   # override with commit/tag as needed\nOUT_DIR=\"$(dirname \"$0\")/images\"\nSCRIPT_DIR=\"$(cd \"$(dirname \"$0\")\" && pwd)\"\n\nmkdir -p \"$OUT_DIR\"\n\necho \"Building base image: ${IMAGE_NS}:${BASE_TAG}\"\ndocker build \\\n  -f \"$SCRIPT_DIR/dfl-base.Dockerfile\" \\\n  -t \"${IMAGE_NS}:${BASE_TAG}\" \\\n  \"$SCRIPT_DIR\"\n\necho \"Building DFL image: ${IMAGE_NS}:${DFL_TAG} (DFL_REF=${DFL_REF})\"\ndocker build \\\n  -f \"$SCRIPT_DIR/dfl.Dockerfile\" \\\n  --build-arg BASE_IMAGE=\"${IMAGE_NS}:${BASE_TAG}\" \\\n  --build-arg DFL_REF=\"${DFL_REF}\" \\\n  -t \"${IMAGE_NS}:${DFL_TAG}\" \\\n  \"$SCRIPT_DIR\"\n\n# Export images to tarballs\nDATE_TAG=\"$(date +%Y%m%d-%H%M%S)\"\nBASE_TAR=\"${OUT_DIR}/${IMAGE_NS//\\//_}-${BASE_TAG}-${DATE_TAG}.tar\"\nDFL_TAR=\"${OUT_DIR}/${IMAGE_NS//\\//_}-${DFL_TAG}-${DATE_TAG}.tar\"\n\necho \"Saving images to tarballs...\"\ndocker save -o \"$BASE_TAR\" \"${IMAGE_NS}:${BASE_TAG}\"\ndocker save -o \"$DFL_TAR\" \"${IMAGE_NS}:${DFL_TAG}\"\n\necho \"Computing SHA-256 checksums...\"\n( cd \"$OUT_DIR\" && sha256sum \"$(basename \"$BASE_TAR\")\" > \"$(basename \"$BASE_TAR\").sha256\" )\n( cd \"$OUT_DIR\" && sha256sum \"$(basename \"$DFL_TAR\")\" > \"$(basename \"$DFL_TAR\").sha256\" )\n\necho \"Done. Artifacts:\"\necho \"  $BASE_TAR\"\necho \"  $BASE_TAR.sha256\"\necho \"  $DFL_TAR\"\necho \"  $DFL_TAR.sha256\"\n\n# Optionally append to evidence ledger if present\nLEDGER=\"$(dirname \"$SCRIPT_DIR\")/evidence/ledger.jsonl\"\nRECORDER=\"$(dirname \"$SCRIPT_DIR\")/evidence/record_image_metadata.sh\"\nif [ -x \"$RECORDER\" ]; then\n  \"$RECORDER\" \"${IMAGE_NS}:${BASE_TAG}\" \"$BASE_TAR\" || true\n  \"$RECORDER\" \"${IMAGE_NS}:${DFL_TAG}\" \"$DFL_TAR\" || true\nfi\n"
    },
    {
      "path": "docker/test_dfl_rtx4090.sh",
      "content": "#!/usr/bin/env bash\nset -euo pipefail\n\nIMAGE=\"custodire/dfl:dfl-cuda11.8-tf2.13.1\"\nWORKDIR_HOST=\"$(cd \"$(dirname \"$0\")\"/.. && pwd)/workspace\"\nmkdir -p \"$WORKDIR_HOST\"\n\nrun() {\n  echo \">>> $*\"\n  eval \"$@\"\n}\n\necho \"Running RTX 4090 validation tests against $IMAGE\"\n\n# Basic nvidia-smi check\nrun docker run --rm --gpus all \"$IMAGE\" nvidia-smi || { echo \"nvidia-smi failed\"; exit 1; }\n\n# TensorFlow GPU presence\nrun docker run --rm --gpus all -e TF_CPP_MIN_LOG_LEVEL=1 \"$IMAGE\" \\\n  python - <<'PY'\nimport tensorflow as tf\nfrom pprint import pprint\nprint('TF version:', tf.__version__)\ngpus = tf.config.list_physical_devices('GPU')\nprint('GPUs:'); pprint(gpus)\nassert gpus, 'No GPUs visible to TensorFlow'\nPY\n\n# ONNX Runtime device must be GPU (CUDA)\nrun docker run --rm --gpus all \"$IMAGE\" \\\n  python - <<'PY'\nimport onnxruntime as ort\nprint('onnxruntime:', ort.__version__)\nprint('device:', ort.get_device())\nassert ort.get_device().lower().startswith('gpu'), 'ONNX Runtime not using GPU'\nPY\n\n# DFL CLI help should print\nrun docker run --rm --gpus all -v \"$WORKDIR_HOST\":/workspace \"$IMAGE\" help\n\necho \"All smoke tests passed.\"\n"
    },
    {
      "path": "docker/dfl-compose.yaml",
      "content": "version: \"3.9\"\n\nservices:\n  dfl:\n    image: custudire/dfl:dfl-cuda11.8-tf2.13.1\n    # Use 'device_requests' for broad compatibility\n    deploy:\n      resources:\n        reservations:\n          devices:\n            - driver: nvidia\n              count: all\n              capabilities: [gpu]\n    # For non-Swarm Compose v2, the shorthand also works:\n    # gpus: all\n    environment:\n      - TF_FORCE_GPU_ALLOW_GROWTH=true\n      - TF_GPU_ALLOCATOR=cuda_malloc_async\n      - NVIDIA_VISIBLE_DEVICES=all\n      - NVIDIA_DRIVER_CAPABILITIES=compute,utility,video\n    working_dir: /workspace\n    volumes:\n      - ../workspace:/workspace\n    entrypoint: [\"/usr/local/bin/dfl\"]\n    command: [\"help\"]\n"
    },
    {
      "path": "docs/dfl_docker_images.md",
      "content": "# DeepFaceLab Docker Images (CUDA 11.8, RTX 4090)\n\nThis project produces two images:\n- Base: CUDA 11.8 + cuDNN + Python 3.10 + TensorFlow GPU 2.13.1 and common ML deps\n- DFL: Above plus DeepFaceLab code (no pretrained models)\n\nHost requirements:\n- NVIDIA GPU (Ada/RTX 4090 supported)\n- NVIDIA driver >= 520.61.05 (recommend 535/545+)\n- Docker Engine + Docker Compose v2\n- nvidia-container-toolkit installed and configured\n\nBuild images:\n- ./docker/build_dfl_images.sh\n  - Args are set at top of script (image namespace, tags, DFL_REF)\n  - Produces tarballs and SHA-256 in docker/images/\n\nValidate on GPU:\n- ./docker/test_dfl_rtx4090.sh\n  - Checks: nvidia-smi, TensorFlow GPU visibility, ONNX Runtime GPU device, DFL CLI help\n\nRun DeepFaceLab:\n- Interactive shell: docker run --rm -it --gpus all -v $(pwd)/workspace:/workspace custudire/dfl:dfl-cuda11.8-tf2.13.1 bash\n- DFL help: docker run --rm --gpus all -v $(pwd)/workspace:/workspace custudire/dfl:dfl-cuda11.8-tf2.13.1 help\n\nDocker Compose:\n- docker compose -f docker/dfl-compose.yaml up --build\n\nNotes:\n- Pretrained models are excluded from the image by design. Place models under workspace/ and bind-mount.\n- If needed, enable NVENC in ffmpeg by ensuring host driver + container capabilities include video (already set); Ubuntu ffmpeg supports nvenc on many installs.\n- To pin DeepFaceLab to a specific commit, set DFL_REF in build script or pass --build-arg DFL_REF=<commit> to the dfl image build.\n- Environment flags set by default: TF_FORCE_GPU_ALLOW_GROWTH=true, TF_GPU_ALLOCATOR=cuda_malloc_async.\n"
    },
    {
      "path": "docs/dfl_training_workflow.md",
      "content": "# DeepFaceLab Training Workflow (Dockerized)\n\nPrereqs:\n- Prepare input data under workspace/: source/ (face A), target/ (face B), and an empty models/ for training artifacts.\n\nTypical steps:\n1) Extract faces\n   - docker run --rm -it --gpus all -v $(pwd)/workspace:/workspace custudire/dfl:dfl-cuda11.8-tf2.13.1 \\\n     extract --input-dir /workspace/source --output-dir /workspace/source_aligned --detector s3fd --max-faces 1 --manual-fix False\n\n2) Train model\n   - docker run --rm -it --gpus all -v $(pwd)/workspace:/workspace custudire/dfl:dfl-cuda11.8-tf2.13.1 \\\n     train --model-dir /workspace/models/SAEHD --training-data-src-dir /workspace/source_aligned --training-data-dst-dir /workspace/target_aligned \\\n     --gpu 0 --write-image-summary False --write-preview-history False\n\n3) Merge/convert\n   - docker run --rm -it --gpus all -v $(pwd)/workspace:/workspace custudire/dfl:dfl-cuda11.8-tf2.13.1 \\\n     merge --input-dir /workspace/target --output-dir /workspace/output --model-dir /workspace/models/SAEHD\n\nTips:\n- Use --manual-fix True for challenging datasets.\n- Monitor VRAM; if OOM occurs, lower batch size or enable allow_growth (already enabled).\n- Prefer onnxruntime-gpu backends for detectors when available to speed up extract.\n- Keep data and models on a persistent mounted volume (workspace/).\n\nCaveats:\n- Command names/flags may vary slightly across DFL revisions. Run `help` to see available actions and options.\n- Some optional dependencies (e.g., dlib) are not included to keep the image light; add as needed.\n"
    },
    {
      "path": "evidence/ledger.template.jsonl",
      "content": "{\n  \"timestamp\": \"2024-01-01T00:00:00Z\",\n  \"image\": \"custodire/dfl:base-cuda11.8-tf2.13.1\",\n  \"artifact_path\": \"docker/images/custodire_dfl-base-cuda11.8-tf2.13.1-20240101-000000.tar\",\n  \"sha256\": \"<sha256>\",\n  \"labels\": {\n    \"oc.title\": \"DeepFaceLab Base (CUDA 11.8, TF 2.13.1)\",\n    \"oc.vendor\": \"Custodire\"\n  },\n  \"notes\": \"Built on host with driver 545.x; see test logs.\"\n}\n{\n  \"timestamp\": \"2024-01-01T00:00:00Z\",\n  \"image\": \"custodire/dfl:dfl-cuda11.8-tf2.13.1\",\n  \"artifact_path\": \"docker/images/custodire_dfl-dfl-cuda11.8-tf2.13.1-20240101-000000.tar\",\n  \"sha256\": \"<sha256>\",\n  \"labels\": {\n    \"oc.title\": \"DeepFaceLab (CUDA 11.8, TF 2.13.1)\",\n    \"oc.vendor\": \"Custodire\"\n  },\n  \"notes\": \"DFL_REF=master; see /opt/dfl/DFL_COMMIT inside image for exact commit.\"\n}\n"
    },
    {
      "path": "evidence/record_image_metadata.sh",
      "content": "#!/usr/bin/env bash\nset -euo pipefail\n\n# Usage: record_image_metadata.sh <image:tag> <path/to/image.tar>\nIMAGE_TAG=\"${1:-}\"\nTAR_PATH=\"${2:-}\"\nLEDGER_FILE=\"$(cd \"$(dirname \"$0\")\" && pwd)/ledger.jsonl\"\n\nif [ -z \"$IMAGE_TAG\" ] || [ -z \"$TAR_PATH\" ]; then\n  echo \"Usage: $0 <image:tag> <path/to/image.tar>\" >&2\n  exit 2\nfi\n\nif [ ! -f \"$TAR_PATH\" ]; then\n  echo \"Artifact not found: $TAR_PATH\" >&2\n  exit 3\nfi\n\nSHA256=$(sha256sum \"$TAR_PATH\" | awk '{print $1}')\nTS=$(date -u +%Y-%m-%dT%H:%M:%SZ)\n\n# Try to read labels from local image if present\nTITLE=$(docker image inspect \"$IMAGE_TAG\" -f '{{ index .Config.Labels \"org.opencontainers.image.title\"}}' 2>/dev/null || true)\nVENDOR=$(docker image inspect \"$IMAGE_TAG\" -f '{{ index .Config.Labels \"org.opencontainers.image.vendor\"}}' 2>/dev/null || true)\n\njq -nc \\\n  --arg ts \"$TS\" \\\n  --arg image \"$IMAGE_TAG\" \\\n  --arg art \"$TAR_PATH\" \\\n  --arg sha \"$SHA256\" \\\n  --arg title \"$TITLE\" \\\n  --arg vendor \"$VENDOR\" \\\n  '{timestamp:$ts, image:$image, artifact_path:$art, sha256:$sha, labels:{\"oc.title\":$title, \"oc.vendor\":$vendor}}' \\\n  >> \"$LEDGER_FILE\"\n\necho \"Recorded to $LEDGER_FILE\"\n"
    }
  ],
  "key_decisions": [
    "Selected CUDA 11.8 with cuDNN via nvidia/cuda:11.8.0-cudnn8-runtime-ubuntu22.04 for Ada/RTX 4090 support.",
    "Pinned TensorFlow GPU to 2.13.1 with tensorflow-addons 0.23.0 for best stability on CUDA 11.8.",
    "Included onnxruntime-gpu 1.16.3, facexlib, and insightface (<0.8) to accelerate detection/segmentation/recognition.",
    "Used Python 3.10 venv at /opt/venv and a non-root user (uid 1000) with /workspace bind-mount target.",
    "Made DeepFaceLab ref configurable via build arg (DFL_REF) to allow pinning commits while defaulting to master.",
    "Explicitly excluded pretrained and workspace assets from the image to avoid redistributing models; rely on mounts.",
    "Set TF runtime env flags (allow_growth, cuda_malloc_async) to improve stability on 24GB Ada GPUs.",
    "Provided build, export, checksum, and evidence logging scripts to integrate with downstream ingest.",
    "Added GPU-aware smoke tests (nvidia-smi, TF GPU, ORT device) and a DFL CLI wrapper entrypoint."
  ],
  "status": "needs_review"
}