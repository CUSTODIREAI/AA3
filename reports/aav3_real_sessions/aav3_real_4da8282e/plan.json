{
  "approach": "Research-pinned, two-image Docker build (CUDA 11.8+/TF-GPU/Py3.10) with reproducible, secure workflows and end-to-end GPU validation on RTX 4090 using multi-stage Dockerfiles, scripted builds/tests, and Custodire ingest tagging.",
  "steps": [
    "Web-research latest DFL, CUDA, cuDNN, TF-GPU, Python",
    "Decide version matrix (CUDA 11.8+, cuDNN, TF-GPU, Py3.10)",
    "Record compatibility notes and breaking changes",
    "Draft base Dockerfile (CUDA 11.8 runtime+devel, Ubuntu 22.04)",
    "Add cuDNN, Python 3.10, venv, system deps (ffmpeg etc.)",
    "Pin pip indexes and wheels for reproducibility",
    "Install TF-GPU (pinned to CUDA/cuDNN versions)",
    "Install core ML libs (numpy, opencv, scikit-image, tqdm, h5py)",
    "Enable TF mixed precision and memory growth defaults",
    "Create non-root user and workspace directories",
    "Label base image with build metadata (OCI labels)",
    "Draft DFL Dockerfile FROM base (multi-stage copy)",
    "Clone DFL repo at pinned commit; install DFL deps",
    "Add entrypoint wrapping common DFL commands",
    "Create workspace tree (/workspace/{data,models,aligned,output})",
    "Add dockerignore to trim build context",
    "Write build script with buildx cache and tags",
    "Write test script: nvidia-smi, TF GPU import, DFL smoke",
    "Add docker-compose with GPU, volumes, resource limits",
    "Build base image via agent.passthrough_shell (docker build)",
    "Build DFL image via agent.passthrough_shell (docker build)",
    "Run GPU detection test in container (--gpus all)",
    "Run TF GPU import test (tf.config.list_physical_devices)",
    "Run DFL extract on small sample video",
    "Run short DFL train (100â€“1000 iters) and log metrics",
    "Run DFL merge to generate test output",
    "Iterate fixes for any dependency/compat issues",
    "Export images (docker save) to docker/images/",
    "Compute SHA-256 of image tarballs and record",
    "Promote build metadata and hashes to Custodire ingest",
    "Write usage docs and workflow guide",
    "Document known-good version matrix and troubleshooting"
  ],
  "unknowns": [
    "Exact latest DeepFaceLab release/commit supporting Ada (RTX 4090) and TF2",
    "Whether upstream DFL requires patches or a maintained TF2 fork for CUDA 11.8+",
    "Best-known TensorFlow GPU version for DFL on CUDA 11.8 (2.12/2.13/2.15/2.16)",
    "Latest CUDA/driver guidance for RTX 4090 in production (R520+ exact)",
    "Matching cuDNN version for chosen CUDA and TF (e.g., cuDNN 8.x.y)",
    "Any DFL dependency pinning for opencv, ffmpeg, scikit-image to avoid breakages",
    "Whether CUDA 12.x offers measurable benefits vs 11.8 for DFL right now",
    "Recommended Python version by DFL maintainers today (3.9 vs 3.10 exact)",
    "Known issues with RTX 4090 + TF eager/mixed-precision in DFL training",
    "DFL scripts expected paths and environment variables for non-Windows Linux",
    "Minimal sample dataset/video for automated smoke tests (license-safe)",
    "Need for additional NVENC/NVDEC codecs in ffmpeg for HEVC/H.264 specifics",
    "Any model-specific weights auto-download behavior that must be disabled",
    "Disk size expectations and realistic layer split to keep images ~5GB/~8GB",
    "Custodire ingest format details for labels, metadata schema and SHA capture"
  ],
  "rationale": "Pinning a compatible version matrix through upfront research minimizes GPU/driver/TensorFlow incompatibilities common with Ada (RTX 4090). Separating a reusable CUDA+TF base from the DFL layer speeds rebuilds, reduces risk, and follows Docker best practices. Multi-stage builds keep images smaller and reproducible. Explicit non-root user, constrained volumes, and no pretrained models improve security and privacy. Scripted builds/tests via agent.passthrough_shell ensure we fetch latest data, actually build, and validate against the acceptance criteria (nvidia-smi, TF GPU import, DFL extract/train/merge). Adding OCI labels and exporting image tarballs with SHA-256 enables Custodire ingest tracking and evidence ledger integration. Detailed docs and a docker-compose file make the environment easy to run and maintain while preserving reproducibility."
}