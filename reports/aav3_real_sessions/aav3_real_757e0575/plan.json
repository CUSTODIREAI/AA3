{
  "approach": "Pin a proven CUDA/TensorFlow toolchain for Ada (RTX 4090), build a minimal CUDA 11.8 + cuDNN base with Python 3.10 and TF-GPU, then layer DeepFaceLab with pinned dependencies. Validate end-to-end (GPU, TF import, DFL extract/train/merge) via automated scripts and capture provenance via OCI labels and saved image tars with SHA-256 for Custodire ingest.",
  "steps": [
    "Web-research compatibility matrix (CUDA, cuDNN, TF, Python, DFL)",
    "Select exact versions and pins for stability",
    "Draft `docker/dfl-base.Dockerfile` skeleton (multi-stage)",
    "Implement base build stage with apt deps and pip cache",
    "Install Python 3.10, pip, venv tools on Ubuntu base",
    "Choose `nvidia/cuda:11.8.0-cudnn8-runtime-ubuntu22.04` base",
    "Install system deps: ffmpeg, git, build-essentials, libgl, x11 libs",
    "Pin TF-GPU (e.g., 2.12.x) matching CUDA 11.8 + cuDNN 8.6",
    "Pin scientific stack (numpy, scipy, numexpr, h5py) to TF constraints",
    "Add OpenCV headless and media IO deps",
    "Create non-root `dfl` user and `/workspace` tree",
    "Add OCI labels with CUDA/TF/Python versions and build date",
    "Draft `docker/dfl.Dockerfile` skeleton (FROM dfl-base)",
    "Clone `iperov/DeepFaceLab` at pinned commit in build stage",
    "Install DFL Python requirements with strict version pins",
    "Create entrypoint/wrapper exposing common DFL workflows",
    "Set up workspace dirs and avoid bundling models/datasets",
    "Add `docker/dfl.dockerignore` to shrink build context",
    "Write `docker/build_dfl_images.sh` (build, tag, save, sha256)",
    "Write `docker/test_dfl_rtx4090.sh` (nvidia-smi, TF import, DFL E2E)",
    "Write `docker/dfl-compose.yaml` with `--gpus all` and mounts",
    "Author `docs/dfl_docker_images.md` (build/run/labels/limits)",
    "Author `docs/dfl_training_workflow.md` (extract/train/merge recipes)",
    "Execute live web lookups and finalize version pins",
    "Build base image and fix dependency conflicts",
    "Build DFL image and resolve runtime issues",
    "Run validation: GPU visible, TF lists GPU, DFL extract",
    "Run quick train (100–1000 iters) and merge test",
    "Record image tars under `docker/images/` and SHA-256",
    "Ingest build metadata into Custodire ledger and tag images"
  ],
  "unknowns": [
    "DeepFaceLab latest stable commit/branch that supports TF 2.x on Linux (exact repo state and tags)",
    "Exact TensorFlow GPU version best with CUDA 11.8 for DFL (2.12.1 vs 2.13.x compatibility)",
    "Required cuDNN minor version (likely 8.6.x) verified for chosen TF",
    "DFL requirements pins for Python 3.10 (numpy/scipy/opencv compatible versions)",
    "Whether DFL still expects TF 1.15 paths for some tools or fully migrated to TF 2.x",
    "Any recent RTX 4090 (Ada) specific issues with TF/XLA or cuDNN",
    "OpenCV headless version that avoids libGL conflicts in CUDA 11.8 image",
    "CLI incantations for Linux DFL workflows (extract/train/merge) and any patches needed",
    "Whether additional detectors (S3FD/MTCNN) auto-download at runtime and how to defer to mounted cache",
    "Host driver version constraints (verify NVIDIA 520+ on target hosts)",
    "Performance tuning flags (e.g., `TF_FORCE_GPU_ALLOW_GROWTH`, `XLA_FLAGS`) for stable training",
    "Compose runtime parameters for GPU memory limits and IPC/shm sizing for training stability"
  ],
  "rationale": "Pinning the CUDA 11.8 + cuDNN 8.6 + TF-GPU toolchain is the most robust path for RTX 4090 (Ada) given TensorFlow’s published wheels and widespread production use. A two-image architecture separates a reusable, cached ML base from the fast-moving DFL layer, improving rebuild times and maintainability. Multi-stage Dockerfiles, non-root user, and tight dependency pins reduce image size and runtime risk. Automated build and validation scripts ensure the images are not only buildable but functionally correct for the full DFL pipeline (extract, train, merge) with GPU acceleration. Capturing OCI labels and exporting `docker save` tars with SHA-256 integrates cleanly with Custodire’s ingest and evidence ledger requirements, enabling reproducible, auditable deepfake generation in an air-gapped workflow."
}