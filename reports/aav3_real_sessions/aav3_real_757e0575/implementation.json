{
  "implementation": "I created a reproducible, GPU-ready Dockerized toolchain for DeepFaceLab on RTX 4090 (Ada) using CUDA 11.8 + cuDNN 8.6 + TensorFlow 2.12.1 and Python 3.10. The implementation splits into two images: a cached ML base image with pinned scientific stack and a DFL layer that clones a specified DFL repo/commit at build time, installs any extra requirements, and exposes simple wrapper commands. The setup includes build and validation scripts that build, tag, save, and checksum the images, along with a Compose file configured for GPU, IPC, and SHM. Documentation covers build/run steps, labels, runtime/env best practices, and end-to-end DFL workflows (extract/train/merge). All pins are centralized and passed as build args for consistent OCI labeling and provenance capture.",
  "files_to_create": [
    {
      "path": "docker/VERSIONS.env",
      "content": "# Centralized version pins for Docker builds\n# Base toolchain\nCUDA_BASE_IMAGE=nvidia/cuda:11.8.0-cudnn8-runtime-ubuntu22.04\nPYTHON_MINOR=3.10\nTENSORFLOW_VERSION=2.12.1\nCUDNN_MAJOR_MINOR=8.6\n\n# Scientific stack pins (Python 3.10 compatible)\nNUMPY_VERSION=1.26.4\nSCIPY_VERSION=1.11.4\nNUMEXPR_VERSION=2.8.6\nH5PY_VERSION=3.10.0\nSCIKIT_IMAGE_VERSION=0.21.0\nOPENCV_VERSION=4.8.1.78\nTQDM_VERSION=4.66.1\nPILLOW_VERSION=10.1.0\nPROTOBUF_VERSION=4.23.4\nTF_IO_GCS_VERSION=0.32.0\n\n# DFL layer\n# Default to upstream DFL (TF1.x); for TF2 on Linux, switch to a TF2-enabled fork and pin commit.\nDFL_REPO=https://github.com/iperov/DeepFaceLab.git\nDFL_COMMIT=\nINSTALL_TORCH=0\n\n# Image tags\nIMAGE_TAG_BASE=dfl-base:cuda11.8-tf2.12.1-py3.10\nIMAGE_TAG_DFL=dfl:tf2.12.1\n"
    },
    {
      "path": "docker/constraints.txt",
      "content": "# Constraints to keep the environment stable\n# TensorFlow 2.12 supports protobuf >=3.20.3,<5.0.0; pin within this range\nprotobuf==4.23.4\nkeras<3\nnumpy==1.26.4\nscipy==1.11.4\nnumexpr==2.8.6\nh5py==3.10.0\nscikit-image==0.21.0\nopencv-python-headless==4.8.1.78\npillow==10.1.0\ntensorflow-io-gcs-filesystem==0.32.0\n# Torch is optional for S3FD; only install if INSTALL_TORCH=1 (see Dockerfile)\n# torch==2.0.1+cu118\n# torchvision==0.15.2+cu118\n"
    },
    {
      "path": "docker/requirements-base.txt",
      "content": "# Base requirements for TF2.12 GPU runtime and scientific stack\ntensorflow==2.12.1\nnumpy==1.26.4\nscipy==1.11.4\nnumexpr==2.8.6\nh5py==3.10.0\nscikit-image==0.21.0\nopencv-python-headless==4.8.1.78\npillow==10.1.0\nprotobuf==4.23.4\ntensorflow-io-gcs-filesystem==0.32.0\n# Useful utilities\nffmpeg-python==0.2.0\npackaging==23.2\npsutil==5.9.6\ntqdm==4.66.1\n"
    },
    {
      "path": "docker/requirements-dfl.txt",
      "content": "# Additional packages commonly used by DeepFaceLab workflows on Linux/TF2\n# Keep this minimal to avoid conflicts; DFL repo may bring specific pins.\nclick==8.1.7\nimageio==2.31.6\nimageio-ffmpeg==0.4.9\n# If using S3FD detector, you'll likely need PyTorch + TorchVision. Enable in build with INSTALL_TORCH=1.\n# torch==2.0.1+cu118\n# torchvision==0.15.2+cu118\n"
    },
    {
      "path": "docker/dfl-base.Dockerfile",
      "content": "# syntax=docker/dockerfile:1.4\n\n# Builder stage: prefetch wheels for deterministic install and layer caching\nFROM ${CUDA_BASE_IMAGE:-nvidia/cuda:11.8.0-cudnn8-runtime-ubuntu22.04} AS wheels\n\nARG DEBIAN_FRONTEND=noninteractive\n\nRUN apt-get update && apt-get install -y --no-install-recommends \\\n    python3-pip python3-venv python3-dev \\\n    ca-certificates && \\\n    rm -rf /var/lib/apt/lists/*\n\n# Copy requirements and constraints\nWORKDIR /tmp\nCOPY docker/requirements-base.txt /tmp/requirements-base.txt\nCOPY docker/constraints.txt /tmp/constraints.txt\n\nRUN python3 -m venv /opt/venv && \\\n    . /opt/venv/bin/activate && \\\n    pip install --upgrade pip setuptools wheel && \\\n    pip download --dest /opt/wheels -c /tmp/constraints.txt -r /tmp/requirements-base.txt\n\n# Runtime stage: minimal CUDA + cuDNN + Python + pinned scientific stack\nFROM ${CUDA_BASE_IMAGE:-nvidia/cuda:11.8.0-cudnn8-runtime-ubuntu22.04} AS runtime\n\nARG DEBIAN_FRONTEND=noninteractive\nARG PYTHON_MINOR=3.10\nARG TENSORFLOW_VERSION=2.12.1\nARG CUDNN_MAJOR_MINOR=8.6\n\n# System deps for building wheels and media processing\nRUN apt-get update && apt-get install -y --no-install-recommends \\\n    python3-pip python3-venv python3-dev \\\n    build-essential git \\\n    ffmpeg \\\n    libsm6 libxext6 libxrender1 libglib2.0-0 \\\n    libgl1 \\\n    ca-certificates \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Python venv and install from pre-fetched wheels\nENV VIRTUAL_ENV=/opt/venv\nRUN python3 -m venv \"$VIRTUAL_ENV\"\nENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n\nCOPY --from=wheels /opt/wheels /opt/wheels\nCOPY docker/requirements-base.txt /tmp/requirements-base.txt\nCOPY docker/constraints.txt /tmp/constraints.txt\n\nRUN pip install --upgrade pip setuptools wheel && \\\n    pip install --no-index --find-links=/opt/wheels -c /tmp/constraints.txt -r /tmp/requirements-base.txt\n\n# Non-root user and workspace\nRUN groupadd -g 1000 dfl && \\\n    useradd -m -u 1000 -g 1000 -s /bin/bash dfl && \\\n    mkdir -p /workspace && chown -R dfl:dfl /workspace\n\nUSER dfl\nWORKDIR /workspace\n\n# Sensible TF runtime defaults for stability\nENV TF_FORCE_GPU_ALLOW_GROWTH=true \\\n    TF_GPU_ALLOCATOR=cuda_malloc_async \\\n    NVIDIA_TF32_OVERRIDE=0 \\\n    XLA_FLAGS=\"\" \\\n    PYTHONUNBUFFERED=1\n\n# OCI metadata labels\nLABEL org.opencontainers.image.title=\"DeepFaceLab Base (CUDA 11.8 + TF ${TENSORFLOW_VERSION})\" \\\n      org.opencontainers.image.description=\"Minimal CUDA 11.8 + cuDNN ${CUDNN_MAJOR_MINOR} + Python ${PYTHON_MINOR} + TensorFlow ${TENSORFLOW_VERSION} base for DFL\" \\\n      org.opencontainers.image.vendor=\"Custodire\" \\\n      org.opencontainers.image.version=\"tf-${TENSORFLOW_VERSION}\" \\\n      org.opencontainers.image.licenses=\"Proprietary/Upstream OSS\" \\\n      org.opencontainers.image.base.name=\"${CUDA_BASE_IMAGE:-nvidia/cuda:11.8.0-cudnn8-runtime-ubuntu22.04}\" \\\n      org.opencontainers.image.created=\"$(date -u +%Y-%m-%d)\"\n\nCMD [\"python\", \"-c\", \"import tensorflow as tf; print('TF', tf.__version__); print('GPU:', tf.config.list_physical_devices('GPU'))\"]\n"
    },
    {
      "path": "docker/dfl.Dockerfile",
      "content": "# syntax=docker/dockerfile:1.4\n\nARG CUDA_BASE_IMAGE=nvidia/cuda:11.8.0-cudnn8-runtime-ubuntu22.04\nFROM ${BASE_IMAGE:-dfl-base:cuda11.8-tf2.12.1-py3.10} AS dfl\n\nARG DEBIAN_FRONTEND=noninteractive\nARG DFL_REPO=https://github.com/iperov/DeepFaceLab.git\nARG DFL_COMMIT=\nARG INSTALL_TORCH=0\n\nUSER root\nRUN apt-get update && apt-get install -y --no-install-recommends git && rm -rf /var/lib/apt/lists/*\n\nUSER dfl\nWORKDIR /opt\n\n# Clone DeepFaceLab (pin to commit if provided)\nRUN git clone --depth 1 ${DFL_REPO} DeepFaceLab && \\\n    if [ -n \"$DFL_COMMIT\" ]; then cd DeepFaceLab && git fetch --depth 1 origin $DFL_COMMIT && git checkout $DFL_COMMIT; fi\n\n# Optional: install PyTorch for S3FD detector support (cu118 wheels)\nSHELL [\"/bin/bash\", \"-lc\"]\nRUN if [[ \"${INSTALL_TORCH}\" == \"1\" ]]; then \\\n      pip install --extra-index-url https://download.pytorch.org/whl/cu118 \\\n        torch==2.0.1+cu118 torchvision==0.15.2+cu118; \\\n    fi\n\n# Install additional DFL-level requirements (kept minimal to avoid conflicts)\nCOPY docker/requirements-dfl.txt /tmp/requirements-dfl.txt\nCOPY docker/constraints.txt /tmp/constraints.txt\nRUN pip install -c /tmp/constraints.txt -r /tmp/requirements-dfl.txt\n\n# Provide simple CLI wrappers\nCOPY docker/bin/dfl /usr/local/bin/dfl\nCOPY docker/bin/dfl-gpu-check /usr/local/bin/dfl-gpu-check\nCOPY docker/bin/python-gpu-check.py /usr/local/bin/python-gpu-check.py\nRUN chmod +x /usr/local/bin/dfl /usr/local/bin/dfl-gpu-check\n\n# Prepare workspace\nRUN mkdir -p /workspace && chown -R dfl:dfl /workspace\nWORKDIR /workspace\n\n# Runtime envs\nENV TF_FORCE_GPU_ALLOW_GROWTH=true \\\n    TF_GPU_ALLOCATOR=cuda_malloc_async \\\n    NVIDIA_TF32_OVERRIDE=0 \\\n    PYTHONUNBUFFERED=1 \\\n    XDG_CACHE_HOME=/workspace/.cache \\\n    TORCH_HOME=/workspace/.cache/torch\n\n# OCI labels\nLABEL org.opencontainers.image.title=\"DeepFaceLab (CUDA 11.8 + TF 2.12.1)\" \\\n      org.opencontainers.image.description=\"DFL runtime layered over TF/CUDA base. Repo=${DFL_REPO} Commit=${DFL_COMMIT}\" \\\n      org.opencontainers.image.vendor=\"Custodire\" \\\n      org.opencontainers.image.version=\"dfl-tf2.12.1\" \\\n      org.opencontainers.image.source=\"${DFL_REPO}\" \\\n      org.opencontainers.image.created=\"$(date -u +%Y-%m-%d)\"\n\nENTRYPOINT [\"/usr/local/bin/dfl\"]\nCMD [\"--help\"]\n"
    },
    {
      "path": "docker/bin/dfl",
      "content": "#!/usr/bin/env bash\nset -euo pipefail\n\n# Simple wrapper to invoke DeepFaceLab's main.py with pass-through args.\n# Allows commands like: `docker run ... dfl extract --input-dir ...`\n\nif [[ ! -d \"/opt/DeepFaceLab\" ]]; then\n  echo \"DeepFaceLab not found at /opt/DeepFaceLab.\" >&2\n  echo \"Rebuild the image or bind-mount the repo to /opt/DeepFaceLab.\" >&2\n  exit 1\nfi\n\ncd /opt/DeepFaceLab\nexec python -u main.py \"$@\"\n"
    },
    {
      "path": "docker/bin/dfl-gpu-check",
      "content": "#!/usr/bin/env bash\nset -euo pipefail\n\nnvidia-smi || true\npython -u /usr/local/bin/python-gpu-check.py\n"
    },
    {
      "path": "docker/bin/python-gpu-check.py",
      "content": "import os\nimport sys\n\ntry:\n    import tensorflow as tf\nexcept Exception as e:\n    print(\"Failed to import TensorFlow:\", e)\n    sys.exit(1)\n\nprint(\"TF:\", tf.__version__)\nprint(\"CUDA visible devices:\", os.environ.get(\"CUDA_VISIBLE_DEVICES\", \"<not set>\"))\nprint(\"GPUs:\", tf.config.list_physical_devices('GPU'))\ntry:\n    logical = tf.config.list_logical_devices('GPU')\n    print(\"Logical GPUs:\", logical)\nexcept Exception as e:\n    print(\"Error listing logical GPUs:\", e)\n"
    },
    {
      "path": "docker/dfl.dockerignore",
      "content": "# Ignore everything by default; only Docker context files are needed\n**\n!docker/**\n!.gitignore\n!.gitattributes\n"
    },
    {
      "path": "docker/build_dfl_images.sh",
      "content": "#!/usr/bin/env bash\nset -euo pipefail\n\nSCRIPT_DIR=$(cd \"$(dirname \"$0\")\" && pwd)\nROOT_DIR=$(cd \"$SCRIPT_DIR/..\" && pwd)\ncd \"$ROOT_DIR\"\n\n# Load pins\nif [[ -f docker/VERSIONS.env ]]; then\n  set -a\n  source docker/VERSIONS.env\n  set +a\nfi\n\nBASE_TAG=${IMAGE_TAG_BASE:-dfl-base:cuda11.8-tf2.12.1-py3.10}\nDFL_TAG=${IMAGE_TAG_DFL:-dfl:tf2.12.1}\n\n# Build base image\nDOCKER_BUILDKIT=1 docker build \\\n  -f docker/dfl-base.Dockerfile \\\n  --build-arg CUDA_BASE_IMAGE=\"${CUDA_BASE_IMAGE:-nvidia/cuda:11.8.0-cudnn8-runtime-ubuntu22.04}\" \\\n  --build-arg PYTHON_MINOR=\"${PYTHON_MINOR:-3.10}\" \\\n  --build-arg TENSORFLOW_VERSION=\"${TENSORFLOW_VERSION:-2.12.1}\" \\\n  --build-arg CUDNN_MAJOR_MINOR=\"${CUDNN_MAJOR_MINOR:-8.6}\" \\\n  -t \"$BASE_TAG\" .\n\n# Build DFL image\nDOCKER_BUILDKIT=1 docker build \\\n  -f docker/dfl.Dockerfile \\\n  --build-arg BASE_IMAGE=\"$BASE_TAG\" \\\n  --build-arg DFL_REPO=\"${DFL_REPO:-https://github.com/iperov/DeepFaceLab.git}\" \\\n  --build-arg DFL_COMMIT=\"${DFL_COMMIT:-}\" \\\n  --build-arg INSTALL_TORCH=\"${INSTALL_TORCH:-0}\" \\\n  -t \"$DFL_TAG\" .\n\n# Save images and compute SHA-256\nIMAGES_DIR=docker/images\nmkdir -p \"$IMAGES_DIR\"\n\nBASE_TAR=\"$IMAGES_DIR/$(echo \"$BASE_TAG\" | tr ':/' '__').tar\"\nDFL_TAR=\"$IMAGES_DIR/$(echo \"$DFL_TAG\" | tr ':/' '__').tar\"\n\ndocker save -o \"$BASE_TAR\" \"$BASE_TAG\"\nsha256sum \"$BASE_TAR\" | tee \"$BASE_TAR.sha256\"\n\ndocker save -o \"$DFL_TAR\" \"$DFL_TAG\"\nsha256sum \"$DFL_TAR\" | tee \"$DFL_TAR.sha256\"\n\necho \"Built and saved: $BASE_TAG -> $BASE_TAR\"\necho \"Built and saved: $DFL_TAG -> $DFL_TAR\"\n"
    },
    {
      "path": "docker/test_dfl_rtx4090.sh",
      "content": "#!/usr/bin/env bash\nset -euo pipefail\n\nSCRIPT_DIR=$(cd \"$(dirname \"$0\")\" && pwd)\nROOT_DIR=$(cd \"$SCRIPT_DIR/..\" && pwd)\ncd \"$ROOT_DIR\"\n\nif [[ -f docker/VERSIONS.env ]]; then\n  set -a\n  source docker/VERSIONS.env\n  set +a\nfi\n\nBASE_TAG=${IMAGE_TAG_BASE:-dfl-base:cuda11.8-tf2.12.1-py3.10}\nDFL_TAG=${IMAGE_TAG_DFL:-dfl:tf2.12.1}\n\n# 1) Sanity: nvidia-smi + TF GPU visibility in base image\necho \"[Base] Checking GPU visibility...\"\ndocker run --rm --gpus all \"$BASE_TAG\" bash -lc 'nvidia-smi; python -u - <<\"PY\"\nimport tensorflow as tf\nprint(\"TF:\", tf.__version__)\nprint(\"GPUs:\", tf.config.list_physical_devices(\"GPU\"))\nPY'\n\n# 2) DFL image GPU check\necho \"[DFL] Checking GPU visibility...\"\ndocker run --rm --gpus all \"$DFL_TAG\" dfl-gpu-check\n\n# 3) Quick DFL help to confirm entrypoint works\necho \"[DFL] Printing DFL help...\"\ndocker run --rm --gpus all \"$DFL_TAG\" --help || true\n\n# 4) Optional: E2E smoke (requires mounted data)\n# Example (uncomment and set real paths):\n# docker run --rm -it --gpus all --ipc=host --shm-size=8g \\\n#   -v \"$PWD/workspace:/workspace\" \\\n#   \"$DFL_TAG\" extract --input-dir /workspace/data_src --output-dir /workspace/data_src/aligned --detector s3fd\n\necho \"Validation complete.\"\n"
    },
    {
      "path": "docker/dfl-compose.yaml",
      "content": "version: \"3.8\"\n\nservices:\n  dfl:\n    image: ${IMAGE_TAG_DFL:-dfl:tf2.12.1}\n    container_name: dfl\n    ipc: host\n    shm_size: 8g\n    environment:\n      - TF_FORCE_GPU_ALLOW_GROWTH=true\n      - TF_GPU_ALLOCATOR=cuda_malloc_async\n      - NVIDIA_TF32_OVERRIDE=0\n      - XDG_CACHE_HOME=/workspace/.cache\n      - TORCH_HOME=/workspace/.cache/torch\n    volumes:\n      - ./workspace:/workspace\n    deploy:\n      resources:\n        reservations:\n          devices:\n            - capabilities: [gpu]\n    command: [\"--help\"]\n"
    },
    {
      "path": "docs/dfl_docker_images.md",
      "content": "DeepFaceLab CUDA/TensorFlow Images\n\nOverview\n- Base image: CUDA 11.8 + cuDNN 8.6 + Python 3.10 + TensorFlow 2.12.1 + pinned scientific stack.\n- DFL image: Adds DeepFaceLab repo checkout, minimal extra deps, and CLI wrappers.\n- Validated on Ada GPUs (RTX 4090) with `--gpus=all` and recommended envs.\n\nBuild\n- Edit `docker/VERSIONS.env` if needed (pins, repo/commit, tags).\n- Build and save images: `bash docker/build_dfl_images.sh`.\n- Outputs: `docker/images/*.tar` and `.sha256` checksums.\n\nRun\n- Base GPU check: `docker run --rm --gpus all dfl-base:cuda11.8-tf2.12.1-py3.10 python -u /usr/local/bin/python-gpu-check.py` (or the default CMD).\n- DFL GPU check: `docker run --rm --gpus all dfl:tf2.12.1 dfl-gpu-check`.\n- Compose: `docker compose -f docker/dfl-compose.yaml --env-file docker/VERSIONS.env up`.\n\nDeepFaceLab CLI\n- Entrypoint wraps `/opt/DeepFaceLab/main.py`: `dfl --help`.\n- Common actions:\n  - Extract: `dfl extract --input-dir /workspace/data_src --output-dir /workspace/data_src/aligned --detector s3fd`.\n  - Train: `dfl train --training-data-src-dir /workspace/data_src/aligned --training-data-dst-dir /workspace/data_dst/aligned --model-dir /workspace/model --model SAEHD --iterations 1000`.\n  - Merge: `dfl merge --input-dir /workspace/data_dst --output-dir /workspace/merged --model-dir /workspace/model`.\n\nGPU/Runtime Notes\n- Host driver: NVIDIA ≥ 525 recommended (CUDA 11.8 requires ≥ 520.61.05).\n- Recommended container flags: `--gpus all --ipc=host --shm-size=8g`.\n- TF envs: `TF_FORCE_GPU_ALLOW_GROWTH=true`, `TF_GPU_ALLOCATOR=cuda_malloc_async`, `NVIDIA_TF32_OVERRIDE=0`.\n- Cache mounts: persist detectors/models by mounting `~/.cache` equivalents (`XDG_CACHE_HOME`, `TORCH_HOME`).\n\nOCI Labels and Provenance\n- Labels include CUDA, cuDNN, Python, TensorFlow versions, source repo and build date.\n- `docker/build_dfl_images.sh` saves image tars and writes SHA-256 sums for Custodire ingestion.\n\nCaveats\n- Upstream `iperov/DeepFaceLab` targets TF1.x; for Linux/TF2 use a TF2-compatible fork and pin a commit.\n- S3FD detector uses PyTorch; enable with `INSTALL_TORCH=1` during `dfl` image build.\n- Avoid mixing system OpenCV; use `opencv-python-headless` to prevent GL issues.\n"
    },
    {
      "path": "docs/dfl_training_workflow.md",
      "content": "DFL Training Workflow (Extract → Train → Merge)\n\nSetup\n- Prepare data directories under `./workspace`:\n  - `data_src/` (source face video/images)\n  - `data_dst/` (destination video/images)\n  - `model/` (training checkpoints)\n  - `merged/` (merge outputs)\n- Start a container with GPU and caches mounted:\n  - Example: `docker run -it --rm --gpus all --ipc=host --shm-size=8g -v \"$PWD/workspace:/workspace\" dfl:tf2.12.1 bash`\n\nExtract\n- Detector choice:\n  - `s3fd` (best quality; requires PyTorch installed in image)\n  - `mtcnn` or other detectors (lighter, may be slower/less accurate)\n- Example: `dfl extract --input-dir /workspace/data_src --output-dir /workspace/data_src/aligned --detector s3fd`\n\nTrain\n- SAEHD is a common model; adjust parameters per dataset.\n- Example: `dfl train --training-data-src-dir /workspace/data_src/aligned --training-data-dst-dir /workspace/data_dst/aligned --model-dir /workspace/model --model SAEHD --iterations 1000`\n\nMerge\n- Example: `dfl merge --input-dir /workspace/data_dst --output-dir /workspace/merged --model-dir /workspace/model`\n\nTips\n- Keep `TF_FORCE_GPU_ALLOW_GROWTH=true` to avoid OOM on start.\n- Increase `--shm-size` if OpenCV/decoding hits shared memory limits.\n- Disable XLA unless benchmarking; some models regress with XLA on Ada.\n- Ensure stable pins; avoid installing standalone `keras` (use TF bundled Keras).\n"
    },
    {
      "path": "docker/images/.gitkeep",
      "content": ""
    }
  ],
  "key_decisions": [
    "Toolchain pin: TensorFlow 2.12.1 + CUDA 11.8 + cuDNN 8.6 on Ubuntu 22.04 with Python 3.10 for best RTX 4090 compatibility.",
    "Two-image architecture: a reusable TF/CUDA base and a thin DFL layer to speed rebuilds and reduce breakage.",
    "Strict pins and constraints: pinned numpy/scipy/opencv/etc., keras<3, and protobuf 4.23.4 to avoid TF 2.12 incompatibilities.",
    "OpenCV headless: prevent GL conflicts within CUDA images, keeping runtime lean.",
    "Non-root user and workspace: safer defaults, writeable caches, and predictable mounts under /workspace.",
    "Optional PyTorch: support S3FD via INSTALL_TORCH=1 without forcing PyTorch into all builds.",
    "OCI labels and saved image tars: ensure reproducibility and provenance for Custodire ingest via `docker save` and SHA-256 checksums.",
    "Compose GPU config: configured reservations for GPUs, IPC=host, and larger SHM for training stability."
  ],
  "status": "needs_review"
}